{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 1000\n",
    "n_items = 100\n",
    "\n",
    "item_cate = ['book', 'movie', 'clothes', '3C', 'shoes', 'makeup', 'groceries']\n",
    "\n",
    "# random generate user data\n",
    "user_id = [i for i in range(n_users)]\n",
    "education = [random.choice([\"High School\", \"Undergraduate\", \"Graduate\", \"PhD\", \"unknown\"]) for _ in range(n_users)]\n",
    "gender = [random.choice([\"Male\", \"Female\",]) for _ in range(n_users)]\n",
    "age = [random.randint(18, 80) for _ in range(n_users)]\n",
    "income = [random.randint(1000, 100000) for _ in range(n_users)]\n",
    "clk_cate_seq = [\n",
    "    [random.choice(item_cate) for _ in range(random.randint(1, 5))] \n",
    "    for _ in range(n_users)\n",
    "]\n",
    "\n",
    "user_df = pd.DataFrame({\n",
    "    \"user_id\": user_id,\n",
    "    \"education\": education,\n",
    "    \"gender\": gender,\n",
    "    \"age\": age,\n",
    "    \"income\": income,\n",
    "    \"clk_cate_seq\": clk_cate_seq\n",
    "})\n",
    "\n",
    "# random generate item data\n",
    "item_id = [i for i in range(n_items)]\n",
    "item_cate = [random.choice(item_cate) for _ in range(n_items)]\n",
    "\n",
    "item_df = pd.DataFrame({\n",
    "    \"item_id\": item_id,\n",
    "    \"item_cate\": item_cate\n",
    "})\n",
    "\n",
    "# random generate click data \n",
    "click_data = []\n",
    "for user in user_id:\n",
    "    for item in item_id:\n",
    "        click_data.append({\n",
    "            \"user_id\": user,\n",
    "            \"item_id\": item,\n",
    "            \"click\": random.choice([0, 1])\n",
    "        })\n",
    "\n",
    "click_df = pd.DataFrame(click_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>clk_cate_seq</th>\n",
       "      <th>item_cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>26481</td>\n",
       "      <td>[clothes, groceries, makeup, clothes, groceries]</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>20503</td>\n",
       "      <td>[book]</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>61327</td>\n",
       "      <td>[clothes, movie]</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>95470</td>\n",
       "      <td>[book]</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>57121</td>\n",
       "      <td>[movie, 3C, movie]</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  click education  gender  age  income  \\\n",
       "0        0        0      0  Graduate  Female   50   26481   \n",
       "1        1        0      0       PhD    Male   65   20503   \n",
       "2        2        0      0   unknown  Female   59   61327   \n",
       "3        3        0      1       PhD  Female   26   95470   \n",
       "4        4        0      1  Graduate    Male   43   57121   \n",
       "\n",
       "                                       clk_cate_seq item_cate  \n",
       "0  [clothes, groceries, makeup, clothes, groceries]        3C  \n",
       "1                                            [book]        3C  \n",
       "2                                  [clothes, movie]        3C  \n",
       "3                                            [book]        3C  \n",
       "4                                [movie, 3C, movie]        3C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join user, item, click data\n",
    "df_samples = click_df.merge(user_df, on=\"user_id\").merge(item_df, on=\"item_id\")\n",
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_configs = [\n",
    "    {\"name\": \"education\", \"dtype\": \"category\", \"emb_dim\": 8},\n",
    "    {\"name\": \"gender\", \"dtype\": \"category\", \"emb_dim\": 8},\n",
    "    {\"name\": \"age\", \"dtype\": \"numerical\", \"norm\": \"std\"},\n",
    "    {\"name\": \"income\", \"dtype\": \"numerical\", \"hash_buckets\": 10, \"emb_dim\": 8},\n",
    "    {\"name\": \"item_cate\", \"dtype\": \"category\", \"emb_dim\": 8, \"hash_buckets\": 10},\n",
    "    {\"name\": \"clk_cate_seq\", \"dtype\": \"category\", \"islist\": True, \"emb_dim\": 8, \"hash_buckets\": 5},\n",
    "\n",
    "    {\"name\": \"item_id\", \"dtype\": \"category\", \"emb_dim\": 8, \"hash_buckets\": 100},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 20000\n"
     ]
    }
   ],
   "source": [
    "from core.sample import traintest_split\n",
    "\n",
    "df_train, df_test = traintest_split(df_samples, test_size=0.2, shuffle=True, group_id='user_id')\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Feature transforming (is_train=True), note that feat_configs will be updated when is_train=True...\n",
      "Processing feature education...\n",
      "Processing feature gender...\n",
      "Processing feature age...\n",
      "Processing feature income...\n",
      "Processing feature item_cate...\n",
      "Processing feature clk_cate_seq...\n",
      "Processing feature item_id...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'education',\n",
       "  'dtype': 'category',\n",
       "  'emb_dim': 8,\n",
       "  'type': 'sparse',\n",
       "  'vocab': {'other': {'idx': 0, 'freq_cnt': 18000},\n",
       "   'high school': {'idx': 1, 'freq_cnt': 16100},\n",
       "   'undergraduate': {'idx': 2, 'freq_cnt': 15800},\n",
       "   'graduate': {'idx': 3, 'freq_cnt': 15600},\n",
       "   'phd': {'idx': 4, 'freq_cnt': 14500}}},\n",
       " {'name': 'gender',\n",
       "  'dtype': 'category',\n",
       "  'emb_dim': 8,\n",
       "  'type': 'sparse',\n",
       "  'vocab': {'male': {'idx': 0, 'freq_cnt': 41500},\n",
       "   'female': {'idx': 1, 'freq_cnt': 38500},\n",
       "   'other': {'idx': 2, 'freq_cnt': 0}}},\n",
       " {'name': 'age',\n",
       "  'dtype': 'numerical',\n",
       "  'norm': 'std',\n",
       "  'type': 'dense',\n",
       "  'mean': 49.87125,\n",
       "  'std': 18.02668121016653,\n",
       "  'min': 18,\n",
       "  'max': 80},\n",
       " {'name': 'income',\n",
       "  'dtype': 'numerical',\n",
       "  'hash_buckets': 10,\n",
       "  'emb_dim': 8,\n",
       "  'type': 'sparse',\n",
       "  'mean': 51158.99,\n",
       "  'std': 29512.678079928733,\n",
       "  'min': 1043,\n",
       "  'max': 99902,\n",
       "  'vocab': [nan,\n",
       "   -inf,\n",
       "   1043.0,\n",
       "   12380.0,\n",
       "   21450.0,\n",
       "   32786.0,\n",
       "   45138.0,\n",
       "   57558.0,\n",
       "   69077.0,\n",
       "   79825.0,\n",
       "   91115.0,\n",
       "   99902.0,\n",
       "   inf]},\n",
       " {'name': 'item_cate',\n",
       "  'dtype': 'category',\n",
       "  'emb_dim': 8,\n",
       "  'hash_buckets': 10,\n",
       "  'type': 'sparse',\n",
       "  'vocab': {6: {'idx': 0, 'freq_cnt': 25600},\n",
       "   8: {'idx': 1, 'freq_cnt': 12800},\n",
       "   1: {'idx': 2, 'freq_cnt': 11200},\n",
       "   7: {'idx': 3, 'freq_cnt': 11200},\n",
       "   9: {'idx': 4, 'freq_cnt': 10400},\n",
       "   2: {'idx': 5, 'freq_cnt': 8800},\n",
       "   'other': {'idx': 6, 'freq_cnt': 0}}},\n",
       " {'name': 'clk_cate_seq',\n",
       "  'dtype': 'category',\n",
       "  'islist': True,\n",
       "  'emb_dim': 8,\n",
       "  'hash_buckets': 5,\n",
       "  'type': 'sparse',\n",
       "  'vocab': {1: {'idx': 0, 'freq_cnt': 107200},\n",
       "   2: {'idx': 1, 'freq_cnt': 67900},\n",
       "   4: {'idx': 2, 'freq_cnt': 38000},\n",
       "   3: {'idx': 3, 'freq_cnt': 30900},\n",
       "   'other': {'idx': 4, 'freq_cnt': 0}}},\n",
       " {'name': 'item_id',\n",
       "  'dtype': 'category',\n",
       "  'emb_dim': 8,\n",
       "  'hash_buckets': 100,\n",
       "  'type': 'sparse',\n",
       "  'vocab': {87: {'idx': 0, 'freq_cnt': 2400},\n",
       "   47: {'idx': 1, 'freq_cnt': 2400},\n",
       "   2: {'idx': 2, 'freq_cnt': 2400},\n",
       "   53: {'idx': 3, 'freq_cnt': 2400},\n",
       "   25: {'idx': 4, 'freq_cnt': 2400},\n",
       "   52: {'idx': 5, 'freq_cnt': 2400},\n",
       "   3: {'idx': 6, 'freq_cnt': 2400},\n",
       "   13: {'idx': 7, 'freq_cnt': 2400},\n",
       "   48: {'idx': 8, 'freq_cnt': 1600},\n",
       "   24: {'idx': 9, 'freq_cnt': 1600},\n",
       "   50: {'idx': 10, 'freq_cnt': 1600},\n",
       "   66: {'idx': 11, 'freq_cnt': 1600},\n",
       "   9: {'idx': 12, 'freq_cnt': 1600},\n",
       "   73: {'idx': 13, 'freq_cnt': 1600},\n",
       "   58: {'idx': 14, 'freq_cnt': 1600},\n",
       "   92: {'idx': 15, 'freq_cnt': 1600},\n",
       "   72: {'idx': 16, 'freq_cnt': 1600},\n",
       "   37: {'idx': 17, 'freq_cnt': 1600},\n",
       "   23: {'idx': 18, 'freq_cnt': 1600},\n",
       "   21: {'idx': 19, 'freq_cnt': 1600},\n",
       "   49: {'idx': 20, 'freq_cnt': 1600},\n",
       "   68: {'idx': 21, 'freq_cnt': 1600},\n",
       "   36: {'idx': 22, 'freq_cnt': 1600},\n",
       "   27: {'idx': 23, 'freq_cnt': 1600},\n",
       "   88: {'idx': 24, 'freq_cnt': 1600},\n",
       "   32: {'idx': 25, 'freq_cnt': 1600},\n",
       "   56: {'idx': 26, 'freq_cnt': 1600},\n",
       "   31: {'idx': 27, 'freq_cnt': 1600},\n",
       "   99: {'idx': 28, 'freq_cnt': 800},\n",
       "   89: {'idx': 29, 'freq_cnt': 800},\n",
       "   91: {'idx': 30, 'freq_cnt': 800},\n",
       "   96: {'idx': 31, 'freq_cnt': 800},\n",
       "   64: {'idx': 32, 'freq_cnt': 800},\n",
       "   15: {'idx': 33, 'freq_cnt': 800},\n",
       "   42: {'idx': 34, 'freq_cnt': 800},\n",
       "   85: {'idx': 35, 'freq_cnt': 800},\n",
       "   17: {'idx': 36, 'freq_cnt': 800},\n",
       "   75: {'idx': 37, 'freq_cnt': 800},\n",
       "   34: {'idx': 38, 'freq_cnt': 800},\n",
       "   78: {'idx': 39, 'freq_cnt': 800},\n",
       "   5: {'idx': 40, 'freq_cnt': 800},\n",
       "   51: {'idx': 41, 'freq_cnt': 800},\n",
       "   8: {'idx': 42, 'freq_cnt': 800},\n",
       "   80: {'idx': 43, 'freq_cnt': 800},\n",
       "   65: {'idx': 44, 'freq_cnt': 800},\n",
       "   94: {'idx': 45, 'freq_cnt': 800},\n",
       "   46: {'idx': 46, 'freq_cnt': 800},\n",
       "   57: {'idx': 47, 'freq_cnt': 800},\n",
       "   55: {'idx': 48, 'freq_cnt': 800},\n",
       "   74: {'idx': 49, 'freq_cnt': 800},\n",
       "   16: {'idx': 50, 'freq_cnt': 800},\n",
       "   4: {'idx': 51, 'freq_cnt': 800},\n",
       "   11: {'idx': 52, 'freq_cnt': 800},\n",
       "   30: {'idx': 53, 'freq_cnt': 800},\n",
       "   63: {'idx': 54, 'freq_cnt': 800},\n",
       "   22: {'idx': 55, 'freq_cnt': 800},\n",
       "   83: {'idx': 56, 'freq_cnt': 800},\n",
       "   61: {'idx': 57, 'freq_cnt': 800},\n",
       "   77: {'idx': 58, 'freq_cnt': 800},\n",
       "   1: {'idx': 59, 'freq_cnt': 800},\n",
       "   70: {'idx': 60, 'freq_cnt': 800},\n",
       "   59: {'idx': 61, 'freq_cnt': 800},\n",
       "   86: {'idx': 62, 'freq_cnt': 800},\n",
       "   6: {'idx': 63, 'freq_cnt': 800},\n",
       "   'other': {'idx': 64, 'freq_cnt': 0}}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.dataset import DataFrameDataset, feature_transform\n",
    "\n",
    "df_train = feature_transform(df_train, feat_configs, is_train=True)\n",
    "feat_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>click</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>clk_cate_seq</th>\n",
       "      <th>item_cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>9</td>\n",
       "      <td>[-100, -100, 1, 3, 2]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>377</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506402</td>\n",
       "      <td>8</td>\n",
       "      <td>[-100, -100, -100, 2, 0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38323</th>\n",
       "      <td>323</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.102324</td>\n",
       "      <td>4</td>\n",
       "      <td>[-100, 3, 0, 2, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78984</th>\n",
       "      <td>984</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.824958</td>\n",
       "      <td>10</td>\n",
       "      <td>[-100, -100, 0, 3, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47801</th>\n",
       "      <td>801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284509</td>\n",
       "      <td>8</td>\n",
       "      <td>[-100, -100, -100, -100, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  click  education  gender       age  income  \\\n",
       "9219       219        0      0          1       1  0.561875       9   \n",
       "4377       377       55      1          2       1  0.506402       8   \n",
       "38323      323       25      1          3       0 -1.102324       4   \n",
       "78984      984       35      1          2       1 -0.824958      10   \n",
       "47801      801        0      0          1       1  0.284509       8   \n",
       "\n",
       "                      clk_cate_seq  item_cate  \n",
       "9219         [-100, -100, 1, 3, 2]          5  \n",
       "4377      [-100, -100, -100, 2, 0]          2  \n",
       "38323           [-100, 3, 0, 2, 0]          0  \n",
       "78984        [-100, -100, 0, 3, 1]          0  \n",
       "47801  [-100, -100, -100, -100, 0]          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Feature transforming (is_train=False) ...\n",
      "Processing feature education...\n",
      "Processing feature gender...\n",
      "Processing feature age...\n",
      "Processing feature income...\n",
      "Processing feature item_cate...\n",
      "Processing feature clk_cate_seq...\n",
      "Processing feature item_id...\n"
     ]
    }
   ],
   "source": [
    "df_test = feature_transform(df_test, feat_configs, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_cols = ['item_id','education','gender','income','item_cate',]\n",
    "seq_sparse_cols = ['clk_cate_seq',]\n",
    "dense_cols = ['age',]\n",
    "target_cols = ['click', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataFrameDataset(\n",
    "    df_train, \n",
    "    sparse_cols, \n",
    "    seq_sparse_cols, \n",
    "    dense_cols, \n",
    "    seq_dense_cols=None, \n",
    "    target_cols=target_cols, \n",
    "    padding_value=-100\n",
    ").to(device)\n",
    "\n",
    "test_dataset = DataFrameDataset(\n",
    "    df_test, \n",
    "    sparse_cols, \n",
    "    seq_sparse_cols, \n",
    "    dense_cols, \n",
    "    seq_dense_cols=None, \n",
    "    target_cols=target_cols, \n",
    "    padding_value=-100\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "{'dense_features': tensor([[ 0.8947],\n",
      "        [-1.7680]]), 'item_id': tensor([[ 8],\n",
      "        [14]], dtype=torch.int32), 'education': tensor([[2],\n",
      "        [0]], dtype=torch.int32), 'gender': tensor([[1],\n",
      "        [1]], dtype=torch.int32), 'income': tensor([[4],\n",
      "        [9]], dtype=torch.int32), 'item_cate': tensor([[0],\n",
      "        [4]], dtype=torch.int32), 'clk_cate_seq': tensor([[-100,    2,    2,    1,    1],\n",
      "        [   3,    2,    0,    2,    0]], dtype=torch.int32)}\n",
      "tensor([[1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print( len(train_dataloader) )\n",
    "for features, labels in DataLoader(train_dataset,batch_size=2,shuffle=True):\n",
    "    print(features)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Model Input: dense_size=1, sparse_size=48\n",
      "DNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (education): Embedding(5, 8)\n",
      "    (gender): Embedding(3, 8)\n",
      "    (income): Embedding(13, 8)\n",
      "    (item_cate): Embedding(7, 8)\n",
      "    (clk_cate_seq): Embedding(5, 8)\n",
      "    (item_id): Embedding(65, 8)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=49, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (logits): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import DNN\n",
    "\n",
    "dnn_hidden_units = [128,64,32]\n",
    "model = DNN(feat_configs, hidden_units=dnn_hidden_units)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),  lr = 0.01, weight_decay = 1e-9)\n",
    "optimizer_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:DNN:[Training] Epoch: 1/3 iter 0/625, Training Loss: 0.6918329000473022\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 100/625, Training Loss: 0.6912421584129333\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 200/625, Training Loss: 0.6936115026473999\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 300/625, Training Loss: 0.6942870020866394\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 400/625, Training Loss: 0.695564866065979\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 500/625, Training Loss: 0.6914029121398926\n",
      "INFO:DNN:[Training] Epoch: 1/3 iter 600/625, Training Loss: 0.6914725303649902\n",
      "INFO:DNN:[Validatoin] Epoch: 1/3, Training Loss: {'total': 0.6934184716224671}, Validation Loss: {'total': 0.6931441327568831}\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 0/625, Training Loss: 0.6925989389419556\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 100/625, Training Loss: 0.6943463683128357\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 200/625, Training Loss: 0.6943218111991882\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 300/625, Training Loss: 0.6908657550811768\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 400/625, Training Loss: 0.6927682757377625\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 500/625, Training Loss: 0.6931485533714294\n",
      "INFO:DNN:[Training] Epoch: 2/3 iter 600/625, Training Loss: 0.6930425763130188\n",
      "INFO:DNN:[Validatoin] Epoch: 2/3, Training Loss: {'total': 0.6933370544433594}, Validation Loss: {'total': 0.6931508301170008}\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 0/625, Training Loss: 0.6929894089698792\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 100/625, Training Loss: 0.6908669471740723\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 200/625, Training Loss: 0.6916669607162476\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 300/625, Training Loss: 0.6909793019294739\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 400/625, Training Loss: 0.6916149258613586\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 500/625, Training Loss: 0.6933019757270813\n",
      "INFO:DNN:[Training] Epoch: 3/3 iter 600/625, Training Loss: 0.6936733722686768\n",
      "INFO:DNN:[Validatoin] Epoch: 3/3, Training Loss: {'total': 0.6932898372650147}, Validation Loss: {'total': 0.6931439771014414}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (embeddings): ModuleDict(\n",
       "    (education): Embedding(5, 8)\n",
       "    (gender): Embedding(3, 8)\n",
       "    (income): Embedding(13, 8)\n",
       "    (item_cate): Embedding(7, 8)\n",
       "    (clk_cate_seq): Embedding(5, 8)\n",
       "    (item_id): Embedding(65, 8)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=49, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (logits): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('DNN')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "    train_dataloader: torch.utils.data.DataLoader, \n",
    "    eval_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    "    early_stopping_rounds: int = None,\n",
    "    best_model_path=None,\n",
    "    final_model_path=None,\n",
    "    ret_model='final'\n",
    "):\n",
    "    eval_losses = []\n",
    "    best_eval_loss = None\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = {'total': 0., }\n",
    "    \n",
    "        # Training \n",
    "        for k, (features, labels) in enumerate(train_dataloader):\n",
    "            # features = features.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()   # zero the parameter gradients\n",
    "            outputs = model(features)\n",
    "            loss = nn.BCEWithLogitsLoss(reduction='mean')(outputs, labels)\n",
    "            loss.backward()        # compute gradients\n",
    "            optimizer.step()       # adjust parameters based on the calculated gradients \n",
    "            train_loss['total'] += loss.item()  # track the loss value \n",
    "            \n",
    "            if k % 100 == 0:\n",
    "                logger.info(f'[Training] Epoch: {epoch}/{num_epochs} iter {k}/{len(train_dataloader)}, Training Loss: {loss.item()}')\n",
    "                \n",
    "        optimizer_scheduler.step()\n",
    "                \n",
    "        for _type, _value in train_loss.items():\n",
    "            train_loss[_type] = _value / len(train_dataloader)\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad(): \n",
    "            model.eval()\n",
    "            eval_loss = {'total': 0.}\n",
    "\n",
    "            for features, labels in eval_dataloader:                \n",
    "                outputs = model(features)\n",
    "                loss = nn.BCEWithLogitsLoss(reduction='mean')(outputs, labels)\n",
    "                eval_loss['total'] += loss.item()  # track the loss value \n",
    "                \n",
    "            for _type, _value in eval_loss.items():\n",
    "                eval_loss[_type] = _value / len(eval_dataloader)\n",
    "                \n",
    "\n",
    "        logger.info(f'[Validatoin] Epoch: {epoch}/{num_epochs}, Training Loss: {train_loss}, Validation Loss: {eval_loss}')\n",
    "\n",
    "        if early_stopping_rounds:\n",
    "            if len(eval_losses) >= early_stopping_rounds:\n",
    "                eval_loss_his_avg = np.mean([v['total'] for v in eval_losses[-early_stopping_rounds:]])\n",
    "                if eval_loss['total'] > eval_loss_his_avg:\n",
    "                    logger.info(f'Early stopping at epoch {epoch}...')\n",
    "                    break\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        if best_model_path:\n",
    "            if best_eval_loss is None or eval_loss['total'] < best_eval_loss:\n",
    "                best_eval_loss = eval_loss['total']\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    if final_model_path:\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        \n",
    "    if ret_model == 'best' and best_model_path:\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    return model\n",
    "\n",
    "train_model(model, \n",
    "    train_dataloader, \n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    num_epochs = 3,\n",
    "    early_stopping_rounds = 10,\n",
    "    best_model_path = 'bestmodel.pth',\n",
    "    final_model_path = 'finalmodel.pth',\n",
    "    ret_model='final'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
